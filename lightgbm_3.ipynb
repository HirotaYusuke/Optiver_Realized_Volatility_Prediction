{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import re\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import scipy as sc\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', 300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train = pd.read_feather('preprocessing/vif_train_0')\n",
    "test = pd.read_feather('preprocessing/X_test_0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['row_id', 'stock_id', 'time_id', 'total_volume_std',\n",
       "       'trade_log_return_realized_volatility', 'trade_order_count_mean',\n",
       "       'trade_pct_change_price_gmean', 'trade_seconds_in_bucket_count_unique',\n",
       "       'trade_size_sum', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['row_id', 'stock_id', 'time_id', 'total_volume_std',\n",
       "       'trade_log_return_realized_volatility', 'trade_order_count_mean',\n",
       "       'trade_pct_change_price_gmean', 'trade_seconds_in_bucket_count_unique',\n",
       "       'trade_size_sum'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def train_and_evaluate(train, test):\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'num_leaves': 100,\n",
    "      'n_jobs': -1,\n",
    "      'learning_rate': 0.1,\n",
    "      'feature_fraction': 0.8,\n",
    "      'bagging_fraction': 0.8,\n",
    "      'verbose': -1\n",
    "    }\n",
    "    # Split features and target\n",
    "    x = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "    y = train['target']\n",
    "    x_test = test.drop(['row_id', 'time_id'], axis = 1)\n",
    "    # Transform stock id to a numeric value\n",
    "    x['stock_id'] = x['stock_id'].astype(int)\n",
    "    x_test['stock_id'] = x_test['stock_id'].astype(int)\n",
    "    \n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 66, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "        val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights, categorical_feature = ['stock_id'])\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 10000, \n",
    "                          early_stopping_rounds = 50, \n",
    "                          verbose_eval = 50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(x_test) / 5\n",
    "        \n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return test_predictions\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Traing and evaluate\n",
    "test_predictions = train_and_evaluate(train, test)\n",
    "# Save test predictions\n",
    "test['target'] = test_predictions\n",
    "test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000543362\ttraining's RMSPE: 0.251662\tvalid_1's rmse: 0.00056542\tvalid_1's RMSPE: 0.260904\n",
      "[100]\ttraining's rmse: 0.000532481\ttraining's RMSPE: 0.246622\tvalid_1's rmse: 0.000563993\tvalid_1's RMSPE: 0.260246\n",
      "[150]\ttraining's rmse: 0.00052535\ttraining's RMSPE: 0.243319\tvalid_1's rmse: 0.000564799\tvalid_1's RMSPE: 0.260618\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's rmse: 0.000531049\ttraining's RMSPE: 0.245959\tvalid_1's rmse: 0.000563877\tvalid_1's RMSPE: 0.260192\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000544025\ttraining's RMSPE: 0.251648\tvalid_1's rmse: 0.000560814\tvalid_1's RMSPE: 0.260101\n",
      "[100]\ttraining's rmse: 0.000533016\ttraining's RMSPE: 0.246556\tvalid_1's rmse: 0.000558826\tvalid_1's RMSPE: 0.25918\n",
      "[150]\ttraining's rmse: 0.000526244\ttraining's RMSPE: 0.243423\tvalid_1's rmse: 0.000558849\tvalid_1's RMSPE: 0.25919\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's rmse: 0.000531628\ttraining's RMSPE: 0.245914\tvalid_1's rmse: 0.000558556\tvalid_1's RMSPE: 0.259054\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000543279\ttraining's RMSPE: 0.251457\tvalid_1's rmse: 0.000561808\tvalid_1's RMSPE: 0.259928\n",
      "[100]\ttraining's rmse: 0.000532655\ttraining's RMSPE: 0.246539\tvalid_1's rmse: 0.000560174\tvalid_1's RMSPE: 0.259172\n",
      "[150]\ttraining's rmse: 0.000525798\ttraining's RMSPE: 0.243365\tvalid_1's rmse: 0.000560275\tvalid_1's RMSPE: 0.259219\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's rmse: 0.000532318\ttraining's RMSPE: 0.246383\tvalid_1's rmse: 0.000560115\tvalid_1's RMSPE: 0.259145\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000544492\ttraining's RMSPE: 0.251615\tvalid_1's rmse: 0.000581921\tvalid_1's RMSPE: 0.270949\n",
      "[100]\ttraining's rmse: 0.000533635\ttraining's RMSPE: 0.246598\tvalid_1's rmse: 0.000584084\tvalid_1's RMSPE: 0.271956\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 0.00054289\ttraining's RMSPE: 0.250875\tvalid_1's rmse: 0.000581356\tvalid_1's RMSPE: 0.270686\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.000543483\ttraining's RMSPE: 0.251838\tvalid_1's rmse: 0.000562441\tvalid_1's RMSPE: 0.259029\n",
      "[100]\ttraining's rmse: 0.000532575\ttraining's RMSPE: 0.246784\tvalid_1's rmse: 0.000560193\tvalid_1's RMSPE: 0.257994\n",
      "[150]\ttraining's rmse: 0.000525849\ttraining's RMSPE: 0.243667\tvalid_1's rmse: 0.000559864\tvalid_1's RMSPE: 0.257842\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's rmse: 0.000529932\ttraining's RMSPE: 0.245559\tvalid_1's rmse: 0.000559738\tvalid_1's RMSPE: 0.257784\n",
      "Our out of folds RMSPE is 0.2614148122812972\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "377410b2ba9df469234bd6844d6b90cef95175d2cd66e3643877be8dcce27c77"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}