{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List\n",
    "import glob\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_dir = 'features'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def pop_row_stock(df):\n",
    "    row = df.pop('row_id')\n",
    "    stock = df.pop('stock_id')\n",
    "    return row, stock\n",
    "\n",
    "def pop_row_stock_time(df):\n",
    "    row = df.pop('row_id')\n",
    "    stock = df.pop('stock_id')\n",
    "    time = df.pop('time_id')\n",
    "    return pd.concat((row, stock, time), axis=1)\n",
    "\n",
    "def load_row_stock_time(_type):\n",
    "    row = pd.read_pickle(f'{data_dir}/row_id_{_type}.ftr')\n",
    "    stock = pd.read_pickle(f'{data_dir}/stock_id_{_type}.ftr')\n",
    "    time = pd.read_pickle(f'{data_dir}/time_id_{_type}.ftr')\n",
    "    return pd.concat((row, stock, time), axis=1)\n",
    "\n",
    "def drop_columns(train, test, excl_columns):\n",
    "    train = train.drop(excl_columns, axis=1)\n",
    "    test = test.drop(excl_columns, axis=1)\n",
    "    return train, test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from my_module import load_all_datasets, load_datasets_sec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\"\"\" def load_datasets_sec(sec_list: [List[int]], excl_columns: Optional[List[str]] = None):\n",
    "    # sec_listに0, 150, 300, 450入れるとそれぞれ追加できる。\n",
    "    # ext_columnsに抜きたいやつを入れると、除外できる。150,300,450の特徴量を消したいときも0秒の時の名前のままで大丈夫。\n",
    "    if sec_list is None:\n",
    "        raise ValueError('sec_listが空です')\n",
    "    \n",
    "    if 0 in sec_list:\n",
    "        sec_list.remove(0)\n",
    "        train = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_train.ftr\")), desc=\"reading all train features from 0s\") if re.search(r'[^0-9]_train.ftr', _path)], axis=1)\n",
    "        test = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_test.ftr\")), desc=\"reading all test features from 0s\") if re.search(r'[^0-9]_test.ftr', _path)], axis=1)\n",
    "        X_train = pd.concat((pop_row_stock_time(train), train), axis=1)\n",
    "        y_train = X_train.pop('target')\n",
    "        X_test = pd.concat((pop_row_stock_time(test), test), axis=1)\n",
    "        \n",
    "        if excl_columns is not None:\n",
    "            X_train, X_test = drop_columns(X_train, X_test, excl_columns)\n",
    "            \n",
    "    else:\n",
    "        X_train = load_row_stock_time(_type='train')\n",
    "        y_train = pd.read_pickle(f'{data_dir}/target_train.ftr')\n",
    "        X_test = load_row_stock_time(_type='test')\n",
    "    \n",
    "    if 150 in sec_list or 300 in sec_list or 450 in sec_list:\n",
    "        for sec in sec_list:\n",
    "            if not sec in [150, 300, 450]:\n",
    "                raise ValueError()\n",
    "            _X_train = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_{sec}_train.ftr\")), desc=f\"reading all train features from {sec}s\")], axis=1).reset_index(drop=True)\n",
    "            _X_test = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_{sec}_test.ftr\")), desc=f\"reading all test features from {sec}s\")], axis=1).reset_index(drop=True)\n",
    "            \n",
    "            if excl_columns is not None:\n",
    "                _X_train, _X_test = drop_columns(_X_train, _X_test, list(map(lambda x: x + f\"_{sec}\", excl_columns)))\n",
    "            \n",
    "            X_train = pd.concat((X_train, _X_train), axis=1)\n",
    "            X_test = pd.concat((X_test, _X_test), axis=1)\n",
    "        \n",
    "    train = pd.concat((X_train, y_train), axis=1)\n",
    "    \n",
    "    return train.reset_index(drop=True), X_test.reset_index(drop=True) \"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' def load_datasets_sec(sec_list: [List[int]], excl_columns: Optional[List[str]] = None):\\n    # sec_listに0, 150, 300, 450入れるとそれぞれ追加できる。\\n    # ext_columnsに抜きたいやつを入れると、除外できる。150,300,450の特徴量を消したいときも0秒の時の名前のままで大丈夫。\\n    if sec_list is None:\\n        raise ValueError(\\'sec_listが空です\\')\\n    \\n    if 0 in sec_list:\\n        sec_list.remove(0)\\n        train = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_train.ftr\")), desc=\"reading all train features from 0s\") if re.search(r\\'[^0-9]_train.ftr\\', _path)], axis=1)\\n        test = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_test.ftr\")), desc=\"reading all test features from 0s\") if re.search(r\\'[^0-9]_test.ftr\\', _path)], axis=1)\\n        X_train = pd.concat((pop_row_stock_time(train), train), axis=1)\\n        y_train = X_train.pop(\\'target\\')\\n        X_test = pd.concat((pop_row_stock_time(test), test), axis=1)\\n        \\n        if excl_columns is not None:\\n            X_train, X_test = drop_columns(X_train, X_test, excl_columns)\\n            \\n    else:\\n        X_train = load_row_stock_time(_type=\\'train\\')\\n        y_train = pd.read_pickle(f\\'{data_dir}/target_train.ftr\\')\\n        X_test = load_row_stock_time(_type=\\'test\\')\\n    \\n    if 150 in sec_list or 300 in sec_list or 450 in sec_list:\\n        for sec in sec_list:\\n            if not sec in [150, 300, 450]:\\n                raise ValueError()\\n            _X_train = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_{sec}_train.ftr\")), desc=f\"reading all train features from {sec}s\")], axis=1).reset_index(drop=True)\\n            _X_test = pd.concat([pd.read_pickle(_path) for _path in tqdm(sorted(glob.glob(f\"{data_dir}/*_{sec}_test.ftr\")), desc=f\"reading all test features from {sec}s\")], axis=1).reset_index(drop=True)\\n            \\n            if excl_columns is not None:\\n                _X_train, _X_test = drop_columns(_X_train, _X_test, list(map(lambda x: x + f\"_{sec}\", excl_columns)))\\n            \\n            X_train = pd.concat((X_train, _X_train), axis=1)\\n            X_test = pd.concat((X_test, _X_test), axis=1)\\n        \\n    train = pd.concat((X_train, y_train), axis=1)\\n    \\n    return train.reset_index(drop=True), X_test.reset_index(drop=True) '"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\"\"\" def load_all_datasets(type: str = \"train\"):\n",
    "    # 全部\n",
    "    train = pd.concat([pd.read_pickle(_path) for _path in tqdm(glob.glob(f\"{data_dir}/*_{type}.ftr\"), desc=\"reading all train features\")], axis=1)\n",
    "    train_row, train_stock = pop_row_stock(train)\n",
    "    X_train = pd.concat((train_row, train_stock, train), axis=1)\n",
    "    y_train = train.pop('target')\n",
    "    \n",
    "    test = pd.concat([pd.read_pickle(_path) for _path in tqdm(glob.glob(f\"{data_dir}/*_test.ftr\"), desc=\"reading all test features\")], axis=1)\n",
    "    test_row, test_stock = pop_row_stock(test)\n",
    "    X_test = pd.concat((test_row, test_stock, test), axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test \"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' def load_all_datasets(type: str = \"train\"):\\n    # 全部\\n    train = pd.concat([pd.read_pickle(_path) for _path in tqdm(glob.glob(f\"{data_dir}/*_{type}.ftr\"), desc=\"reading all train features\")], axis=1)\\n    train_row, train_stock = pop_row_stock(train)\\n    X_train = pd.concat((train_row, train_stock, train), axis=1)\\n    y_train = train.pop(\\'target\\')\\n    \\n    test = pd.concat([pd.read_pickle(_path) for _path in tqdm(glob.glob(f\"{data_dir}/*_test.ftr\"), desc=\"reading all test features\")], axis=1)\\n    test_row, test_stock = pop_row_stock(test)\\n    X_test = pd.concat((test_row, test_stock, test), axis=1)\\n    \\n    return X_train, y_train, X_test '"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\"\"\" def load_datasets(feats):\n",
    "    # 指定したやつだけ\n",
    "    train = pd.concat([pd.read_pickle(f'{data_dir}/{f}_train.ftr') for f in tqdm(feats, desc=\"reading train features\")], axis=1)\n",
    "    train_row = pd.read_pickle(f'{data_dir}/row_id_train.ftr')\n",
    "    train_stock = pd.read_pickle(f'{data_dir}/stock_id_train.ftr')\n",
    "    X_train = pd.concat((train_row, train_stock, train), axis=1)\n",
    "    y_train = pd.read_pickle(f'{data_dir}/target_train.ftr')\n",
    "    \n",
    "    X_test = pd.concat([pd.read_pickle(f'{data_dir}/{f}_test.ftr') for f in tqdm(feats, desc=\"reading test features\")], axis=1)\n",
    "    test_row = pd.read_pickle(f'{data_dir}/row_id_train.ftr')\n",
    "    test_stock = pd.read_pickle(f'{data_dir}/stock_id_train.ftr')\n",
    "    X_test = pd.concat((test_row, test_stock, train), axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test \"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' def load_datasets(feats):\\n    # 指定したやつだけ\\n    train = pd.concat([pd.read_pickle(f\\'{data_dir}/{f}_train.ftr\\') for f in tqdm(feats, desc=\"reading train features\")], axis=1)\\n    train_row = pd.read_pickle(f\\'{data_dir}/row_id_train.ftr\\')\\n    train_stock = pd.read_pickle(f\\'{data_dir}/stock_id_train.ftr\\')\\n    X_train = pd.concat((train_row, train_stock, train), axis=1)\\n    y_train = pd.read_pickle(f\\'{data_dir}/target_train.ftr\\')\\n    \\n    X_test = pd.concat([pd.read_pickle(f\\'{data_dir}/{f}_test.ftr\\') for f in tqdm(feats, desc=\"reading test features\")], axis=1)\\n    test_row = pd.read_pickle(f\\'{data_dir}/row_id_train.ftr\\')\\n    test_stock = pd.read_pickle(f\\'{data_dir}/stock_id_train.ftr\\')\\n    X_test = pd.concat((test_row, test_stock, train), axis=1)\\n    \\n    return X_train, y_train, X_test '"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X_train, y_train, X_test =  load_all_datasets()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "reading all train features: 100%|██████████| 160/160 [00:25<00:00,  6.24it/s]\n",
      "reading all test features: 100%|██████████| 159/159 [00:00<00:00, 807.75it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VIF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from spica.VIF import vif_search, vif_decrese_method"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "drop_X_train = X_train.copy()\n",
    "drop_X_train = X_train.dropna(inplace=True)\n",
    "drop_X_train = X_train.drop(['row_id','stock_id','time_id'], axis=1)\n",
    "drop_X_train.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df_vif = vif_search(drop_X_train)\n",
    "df_vif"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 157/157 [00:20<00:00,  7.50it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.504015e+04</td>\n",
       "      <td>wap2_mean_300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.668878e+03</td>\n",
       "      <td>log_return1_realized_volatility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.071760e+01</td>\n",
       "      <td>trade_seconds_in_bucket_count_unique_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.817729e+01</td>\n",
       "      <td>trade_size_sum_450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.188738e+02</td>\n",
       "      <td>wap2_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>6.327129e+03</td>\n",
       "      <td>log_return2_realized_volatility_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5.892770e+04</td>\n",
       "      <td>price_spread_sum_150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.082250e+04</td>\n",
       "      <td>total_volume_mean_300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3.291867e+08</td>\n",
       "      <td>wap2_sum_300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>7.584788e+02</td>\n",
       "      <td>price_spread_std</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VIF Factor                                  features\n",
       "0    2.504015e+04                             wap2_mean_300\n",
       "1    3.668878e+03           log_return1_realized_volatility\n",
       "2    6.071760e+01  trade_seconds_in_bucket_count_unique_150\n",
       "3    1.817729e+01                        trade_size_sum_450\n",
       "4    2.188738e+02                                  wap2_std\n",
       "..            ...                                       ...\n",
       "152  6.327129e+03       log_return2_realized_volatility_150\n",
       "153  5.892770e+04                      price_spread_sum_150\n",
       "154  1.082250e+04                     total_volume_mean_300\n",
       "155  3.291867e+08                              wap2_sum_300\n",
       "156  7.584788e+02                          price_spread_std\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "vif_X_train = vif_decrese_method(drop_X_train, 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 157/157 [00:10<00:00, 15.63it/s]\n",
      "157it [00:00, 4524.10it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "drop_X_train = X_train.copy()\n",
    "drop_X_train = X_train.dropna(inplace=True)\n",
    "drop_X_train = X_train.drop(['row_id','stock_id','time_id'], axis=1)\n",
    "drop_X_train.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "drop_list = []\n",
    "for columns in tqdm(drop_X_train.columns):\n",
    "    if columns not in vif_X_train.columns:\n",
    "        drop_list.append(columns)\n",
    "\n",
    "drop_list"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 282257.06it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['wap2_mean_300',\n",
       " 'log_return1_realized_volatility',\n",
       " 'trade_seconds_in_bucket_count_unique_150',\n",
       " 'trade_size_sum_450',\n",
       " 'wap2_std',\n",
       " 'total_volume_std_150',\n",
       " 'log_return2_std_300',\n",
       " 'trade_seconds_in_bucket_count_unique',\n",
       " 'log_return1_std_150',\n",
       " 'wap1_std_300',\n",
       " 'price_spread_std_450',\n",
       " 'pct_change_wap1_gmean_450',\n",
       " 'wap2_std_300',\n",
       " 'wap1_std_450',\n",
       " 'bid_spread_std_300',\n",
       " 'total_volume_sum_450',\n",
       " 'volume_imbalance_mean_450',\n",
       " 'total_volume_sum_300',\n",
       " 'price_spread_sum',\n",
       " 'total_volume_std_450',\n",
       " 'volume_imbalance_sum_150',\n",
       " 'total_volume_mean_450',\n",
       " 'log_return2_mean_300',\n",
       " 'wap2_std_450',\n",
       " 'log_return2_realized_volatility_450',\n",
       " 'total_volume_std',\n",
       " 'log_return2_realized_volatility',\n",
       " 'log_return2_sum',\n",
       " 'trade_order_count_mean_300',\n",
       " 'log_return1_sum',\n",
       " 'ask_spread_std_450',\n",
       " 'pct_change_wap2_gmean_450',\n",
       " 'ask_spread_mean_150',\n",
       " 'trade_size_sum_300',\n",
       " 'bid_spread_std',\n",
       " 'log_return2_std_150',\n",
       " 'log_return1_sum_300',\n",
       " 'wap_balance_std_450',\n",
       " 'log_return1_mean_300',\n",
       " 'total_volume_std_300',\n",
       " 'volume_imbalance_sum_300',\n",
       " 'volume_imbalance_sum_450',\n",
       " 'pct_change_wap2_gmean_150',\n",
       " 'trade_size_sum',\n",
       " 'wap2_std_150',\n",
       " 'total_volume_mean',\n",
       " 'trade_pct_change_price_gmean_150',\n",
       " 'wap_balance_std_300',\n",
       " 'wap2_sum_450',\n",
       " 'ask_spread_std',\n",
       " 'wap_balance_mean_150',\n",
       " 'log_return1_sum_150',\n",
       " 'volume_imbalance_std_450',\n",
       " 'wap_balance_sum',\n",
       " 'ask_spread_sum_450',\n",
       " 'log_return2_realized_volatility_300',\n",
       " 'log_return2_mean_150',\n",
       " 'volume_imbalance_std',\n",
       " 'wap1_mean_450',\n",
       " 'trade_log_return_realized_volatility_300',\n",
       " 'wap_balance_std',\n",
       " 'trade_order_count_mean_150',\n",
       " 'bid_spread_sum',\n",
       " 'trade_size_sum_150',\n",
       " 'wap_balance_sum_150',\n",
       " 'price_spread_mean_300',\n",
       " 'log_return2_mean_450',\n",
       " 'wap2_mean_150',\n",
       " 'bid_spread_mean_300',\n",
       " 'trade_pct_change_price_gmean',\n",
       " 'log_return1_realized_volatility_150',\n",
       " 'pct_change_wap2_gmean_300',\n",
       " 'bid_spread_sum_300',\n",
       " 'bid_spread_mean',\n",
       " 'log_return2_sum_150',\n",
       " 'pct_change_wap1_gmean_300',\n",
       " 'pct_change_wap1_gmean_150',\n",
       " 'volume_imbalance_mean',\n",
       " 'bid_spread_sum_150',\n",
       " 'ask_spread_sum',\n",
       " 'pct_change_wap1_gmean',\n",
       " 'volume_imbalance_std_300',\n",
       " 'trade_seconds_in_bucket_count_unique_300',\n",
       " 'wap1_std',\n",
       " 'wap_balance_sum_450',\n",
       " 'ask_spread_std_150',\n",
       " 'volume_imbalance_mean_150',\n",
       " 'price_spread_sum_300',\n",
       " 'ask_spread_mean',\n",
       " 'wap1_mean_300',\n",
       " 'total_volume_sum',\n",
       " 'total_volume_sum_150',\n",
       " 'log_return1_mean_150',\n",
       " 'wap1_sum_300',\n",
       " 'bid_spread_mean_450',\n",
       " 'price_spread_mean_450',\n",
       " 'log_return2_sum_300',\n",
       " 'trade_pct_change_price_gmean_450',\n",
       " 'ask_spread_sum_300',\n",
       " 'volume_imbalance_mean_300',\n",
       " 'log_return2_mean',\n",
       " 'log_return1_mean_450',\n",
       " 'log_return2_sum_450',\n",
       " 'log_return1_realized_volatility_450',\n",
       " 'wap2_mean_450',\n",
       " 'wap_balance_mean_300',\n",
       " 'bid_spread_std_450',\n",
       " 'ask_spread_mean_300',\n",
       " 'price_spread_mean',\n",
       " 'wap1_std_150',\n",
       " 'wap_balance_mean',\n",
       " 'log_return1_std_450',\n",
       " 'bid_spread_sum_450',\n",
       " 'price_spread_std_300',\n",
       " 'wap_balance_std_150',\n",
       " 'ask_spread_sum_150',\n",
       " 'volume_imbalance_std_150',\n",
       " 'log_return2_std_450',\n",
       " 'wap1_sum_150',\n",
       " 'wap1_sum',\n",
       " 'total_volume_mean_150',\n",
       " 'wap1_mean',\n",
       " 'volume_imbalance_sum',\n",
       " 'bid_spread_std_150',\n",
       " 'ask_spread_mean_450',\n",
       " 'wap_balance_mean_450',\n",
       " 'bid_spread_mean_150',\n",
       " 'price_spread_sum_450',\n",
       " 'trade_order_count_mean',\n",
       " 'wap1_mean_150',\n",
       " 'trade_pct_change_price_gmean_300',\n",
       " 'wap2_sum_150',\n",
       " 'log_return1_std',\n",
       " 'wap_balance_sum_300',\n",
       " 'trade_log_return_realized_volatility_150',\n",
       " 'log_return2_std',\n",
       " 'pct_change_wap2_gmean',\n",
       " 'wap1_sum_450',\n",
       " 'price_spread_std_150',\n",
       " 'wap2_mean',\n",
       " 'ask_spread_std_300',\n",
       " 'log_return1_sum_450',\n",
       " 'price_spread_mean_150',\n",
       " 'log_return1_std_300',\n",
       " 'wap2_sum',\n",
       " 'trade_log_return_realized_volatility',\n",
       " 'log_return1_mean',\n",
       " 'log_return1_realized_volatility_300',\n",
       " 'log_return2_realized_volatility_150',\n",
       " 'price_spread_sum_150',\n",
       " 'total_volume_mean_300',\n",
       " 'wap2_sum_300',\n",
       " 'price_spread_std']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "drop_list.append('row_id')\n",
    "drop_list.append('stock_id')\n",
    "drop_list.append('time_id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "vif_X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>trade_log_return_realized_volatility_450</th>\n",
       "      <th>trade_order_count_mean_450</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_450</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  trade_log_return_realized_volatility_450  \\\n",
       "0    0.008000                                  0.000000   \n",
       "1    0.005865                                  0.000122   \n",
       "2    0.005027                                  0.000306   \n",
       "3    0.004300                                  0.000049   \n",
       "4    0.005052                                  0.000047   \n",
       "..        ...                                       ...   \n",
       "343  0.002271                                  0.000431   \n",
       "344  0.002123                                  0.000058   \n",
       "345  0.003127                                  0.000142   \n",
       "346  0.005852                                  0.001000   \n",
       "347  0.002192                                  0.000079   \n",
       "\n",
       "     trade_order_count_mean_450  trade_seconds_in_bucket_count_unique_450  \n",
       "0                           2.5                                       2.0  \n",
       "1                           1.0                                       1.0  \n",
       "2                          12.0                                       1.0  \n",
       "3                           7.5                                       2.0  \n",
       "4                           9.0                                       1.0  \n",
       "..                          ...                                       ...  \n",
       "343                         3.0                                       1.0  \n",
       "344                         9.0                                       1.0  \n",
       "345                         1.0                                       1.0  \n",
       "346                         4.5                                       2.0  \n",
       "347                         2.0                                       1.0  \n",
       "\n",
       "[348 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "train_0, X_test_0 = load_datasets_sec(sec_list = [0], excl_columns=[])\n",
    "train_150, X_test_150 = load_datasets_sec(sec_list = [150], excl_columns=[])\n",
    "train_300, X_test_300 = load_datasets_sec(sec_list = [300], excl_columns=[])\n",
    "train_450, X_test_450 = load_datasets_sec(sec_list = [450], excl_columns=[])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "reading all train features from 0s: 100%|██████████| 160/160 [00:02<00:00, 58.26it/s]\n",
      "reading all test features from 0s: 100%|██████████| 159/159 [00:00<00:00, 11430.97it/s]\n",
      "reading all train features from 150s: 100%|██████████| 39/39 [00:01<00:00, 21.33it/s]\n",
      "reading all test features from 150s: 100%|██████████| 39/39 [00:00<00:00, 2403.37it/s]\n",
      "reading all train features from 300s: 100%|██████████| 39/39 [00:02<00:00, 17.42it/s]\n",
      "reading all test features from 300s: 100%|██████████| 39/39 [00:00<00:00, 3379.15it/s]\n",
      "reading all train features from 450s: 100%|██████████| 39/39 [00:02<00:00, 15.56it/s]\n",
      "reading all test features from 450s: 100%|██████████| 39/39 [00:00<00:00, 2784.83it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "drop_0_train = train_0.copy()\n",
    "drop_0_train = train_0.dropna(inplace=True)\n",
    "drop_0_train = train_0.drop(['row_id','stock_id','time_id'], axis=1)\n",
    "drop_0_train.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "vif_train_0 = vif_decrese_method(drop_0_train, 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 24.09it/s]\n",
      "40it [00:00, 3337.22it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "drop_150_train = train_150.copy()\n",
    "drop_150_train = train_150.dropna(inplace=True)\n",
    "drop_150_train = train_150.drop(['row_id','stock_id','time_id'], axis=1)\n",
    "drop_150_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "drop_300_train = train_300.copy()\n",
    "drop_300_train = train_300.dropna(inplace=True)\n",
    "drop_300_train = train_300.drop(['row_id','stock_id','time_id'], axis=1)\n",
    "drop_300_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "drop_450_train = train_450.copy()\n",
    "drop_450_train = train_450.dropna(inplace=True)\n",
    "drop_450_train = train_450.drop(['row_id','stock_id','time_id'], axis=1)\n",
    "drop_450_train.reset_index(drop=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "vif_train_150 = vif_decrese_method(drop_150_train, 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 33.31it/s]\n",
      "40it [00:00, 2977.85it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "vif_train_300 = vif_decrese_method(drop_300_train, 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 28.55it/s]\n",
      "40it [00:00, 2272.97it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "vif_train_450 = vif_decrese_method(drop_450_train, 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  8.30it/s]\n",
      "40it [00:00, 6433.97it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(vif_X_train.columns)\n",
    "print(vif_train_0.columns)\n",
    "print(vif_train_150.columns)\n",
    "print(vif_train_300.columns)\n",
    "print(vif_train_450.columns)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['target', 'trade_log_return_realized_volatility_450',\n",
      "       'trade_order_count_mean_450',\n",
      "       'trade_seconds_in_bucket_count_unique_450'],\n",
      "      dtype='object')\n",
      "Index(['total_volume_std', 'trade_log_return_realized_volatility',\n",
      "       'trade_order_count_mean', 'trade_pct_change_price_gmean',\n",
      "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum', 'target'],\n",
      "      dtype='object')\n",
      "Index(['bid_spread_std_150', 'total_volume_std_150',\n",
      "       'trade_log_return_realized_volatility_150',\n",
      "       'trade_order_count_mean_150', 'trade_pct_change_price_gmean_150',\n",
      "       'trade_seconds_in_bucket_count_unique_150', 'trade_size_sum_150',\n",
      "       'volume_imbalance_std_150', 'target'],\n",
      "      dtype='object')\n",
      "Index(['ask_spread_std_300', 'bid_spread_std_300', 'price_spread_std_300',\n",
      "       'total_volume_std_300', 'trade_log_return_realized_volatility_300',\n",
      "       'trade_order_count_mean_300', 'trade_pct_change_price_gmean_300',\n",
      "       'trade_seconds_in_bucket_count_unique_300', 'trade_size_sum_300',\n",
      "       'volume_imbalance_std_300', 'target'],\n",
      "      dtype='object')\n",
      "Index(['ask_spread_std_450', 'bid_spread_std_450', 'price_spread_std_450',\n",
      "       'total_volume_std_450', 'trade_log_return_realized_volatility_450',\n",
      "       'trade_order_count_mean_450', 'trade_pct_change_price_gmean_450',\n",
      "       'trade_seconds_in_bucket_count_unique_450', 'trade_size_sum_450',\n",
      "       'volume_imbalance_std_450', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "columns_list = ['trade_log_return_realized_volatility','trade_order_count_mean',\n",
    "'trade_seconds_in_bucket_count_unique','trade_pct_change_price_gmean','trade_size_sum',\n",
    "'volume_imbalance_std']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "vif_0 = vif_search(drop_0_train)\n",
    "vif_0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.209452e+03</td>\n",
       "      <td>ask_spread_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.466646e+01</td>\n",
       "      <td>ask_spread_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.241734e+04</td>\n",
       "      <td>ask_spread_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.542618e+03</td>\n",
       "      <td>bid_spread_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.144324e+01</td>\n",
       "      <td>bid_spread_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.231970e+04</td>\n",
       "      <td>bid_spread_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.150105e+01</td>\n",
       "      <td>log_return1_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.504847e+02</td>\n",
       "      <td>log_return1_realized_volatility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.434474e+02</td>\n",
       "      <td>log_return1_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.390389e+01</td>\n",
       "      <td>log_return1_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.363362e+01</td>\n",
       "      <td>log_return2_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.977149e+02</td>\n",
       "      <td>log_return2_realized_volatility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.316751e+02</td>\n",
       "      <td>log_return2_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.693106e+01</td>\n",
       "      <td>log_return2_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.547624e+01</td>\n",
       "      <td>pct_change_wap1_gmean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.521515e+01</td>\n",
       "      <td>pct_change_wap2_gmean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.146497e+02</td>\n",
       "      <td>price_spread_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.402391e+01</td>\n",
       "      <td>price_spread_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.485677e+02</td>\n",
       "      <td>price_spread_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.593755e+02</td>\n",
       "      <td>total_volume_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.963786e+00</td>\n",
       "      <td>total_volume_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.445476e+02</td>\n",
       "      <td>total_volume_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.388486e+00</td>\n",
       "      <td>trade_log_return_realized_volatility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.062867e+00</td>\n",
       "      <td>trade_order_count_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.354246e+00</td>\n",
       "      <td>trade_pct_change_price_gmean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.445753e+00</td>\n",
       "      <td>trade_seconds_in_bucket_count_unique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.612858e+00</td>\n",
       "      <td>trade_size_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.282811e+02</td>\n",
       "      <td>volume_imbalance_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.283371e+01</td>\n",
       "      <td>volume_imbalance_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.370348e+02</td>\n",
       "      <td>volume_imbalance_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.710798e+07</td>\n",
       "      <td>wap1_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.992363e+01</td>\n",
       "      <td>wap1_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.175772e+07</td>\n",
       "      <td>wap1_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.670123e+07</td>\n",
       "      <td>wap2_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.881717e+01</td>\n",
       "      <td>wap2_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.178553e+07</td>\n",
       "      <td>wap2_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.898923e+02</td>\n",
       "      <td>wap_balance_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.286503e+01</td>\n",
       "      <td>wap_balance_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.492268e+02</td>\n",
       "      <td>wap_balance_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.941316e+00</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VIF Factor                              features\n",
       "0   2.209452e+03                       ask_spread_mean\n",
       "1   2.466646e+01                        ask_spread_std\n",
       "2   1.241734e+04                        ask_spread_sum\n",
       "3   2.542618e+03                       bid_spread_mean\n",
       "4   1.144324e+01                        bid_spread_std\n",
       "5   1.231970e+04                        bid_spread_sum\n",
       "6   3.150105e+01                      log_return1_mean\n",
       "7   4.504847e+02       log_return1_realized_volatility\n",
       "8   3.434474e+02                       log_return1_std\n",
       "9   6.390389e+01                       log_return1_sum\n",
       "10  2.363362e+01                      log_return2_mean\n",
       "11  2.977149e+02       log_return2_realized_volatility\n",
       "12  3.316751e+02                       log_return2_std\n",
       "13  3.693106e+01                       log_return2_sum\n",
       "14  6.547624e+01                 pct_change_wap1_gmean\n",
       "15  6.521515e+01                 pct_change_wap2_gmean\n",
       "16  2.146497e+02                     price_spread_mean\n",
       "17  2.402391e+01                      price_spread_std\n",
       "18  6.485677e+02                      price_spread_sum\n",
       "19  5.593755e+02                     total_volume_mean\n",
       "20  7.963786e+00                      total_volume_std\n",
       "21  5.445476e+02                      total_volume_sum\n",
       "22  9.388486e+00  trade_log_return_realized_volatility\n",
       "23  4.062867e+00                trade_order_count_mean\n",
       "24  1.354246e+00          trade_pct_change_price_gmean\n",
       "25  3.445753e+00  trade_seconds_in_bucket_count_unique\n",
       "26  4.612858e+00                        trade_size_sum\n",
       "27  2.282811e+02                 volume_imbalance_mean\n",
       "28  1.283371e+01                  volume_imbalance_std\n",
       "29  2.370348e+02                  volume_imbalance_sum\n",
       "30  6.710798e+07                             wap1_mean\n",
       "31  4.992363e+01                              wap1_std\n",
       "32  7.175772e+07                              wap1_sum\n",
       "33  6.670123e+07                             wap2_mean\n",
       "34  3.881717e+01                              wap2_std\n",
       "35  7.178553e+07                              wap2_sum\n",
       "36  1.898923e+02                      wap_balance_mean\n",
       "37  2.286503e+01                       wap_balance_std\n",
       "38  1.492268e+02                       wap_balance_sum\n",
       "39  7.941316e+00                                target"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "drop_list_0 = []\n",
    "for columns in tqdm(drop_0_train.columns):\n",
    "    if columns not in vif_train_0.columns:\n",
    "        drop_list_0.append(columns)\n",
    "\n",
    "drop_list_0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 49887.65it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ask_spread_mean',\n",
       " 'ask_spread_std',\n",
       " 'ask_spread_sum',\n",
       " 'bid_spread_mean',\n",
       " 'bid_spread_std',\n",
       " 'bid_spread_sum',\n",
       " 'log_return1_mean',\n",
       " 'log_return1_realized_volatility',\n",
       " 'log_return1_std',\n",
       " 'log_return1_sum',\n",
       " 'log_return2_mean',\n",
       " 'log_return2_realized_volatility',\n",
       " 'log_return2_std',\n",
       " 'log_return2_sum',\n",
       " 'pct_change_wap1_gmean',\n",
       " 'pct_change_wap2_gmean',\n",
       " 'price_spread_mean',\n",
       " 'price_spread_std',\n",
       " 'price_spread_sum',\n",
       " 'total_volume_mean',\n",
       " 'total_volume_sum',\n",
       " 'volume_imbalance_mean',\n",
       " 'volume_imbalance_std',\n",
       " 'volume_imbalance_sum',\n",
       " 'wap1_mean',\n",
       " 'wap1_std',\n",
       " 'wap1_sum',\n",
       " 'wap2_mean',\n",
       " 'wap2_std',\n",
       " 'wap2_sum',\n",
       " 'wap_balance_mean',\n",
       " 'wap_balance_std',\n",
       " 'wap_balance_sum']"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "for columns in tqdm(drop_list_0):\n",
    "    if columns in columns_list:\n",
    "        print(columns)\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 77368.38it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "volume_imbalance_std\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "from my_module import load_datasets_sec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "columns_list.remove('volume_imbalance_std')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "train_0, X_test_0 = load_datasets_sec(sec_list = [0, 150, 300, 450], excl_columns= drop_list_0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "reading all train features from 0s: 100%|██████████| 160/160 [00:06<00:00, 23.65it/s]\n",
      "reading all test features from 0s: 100%|██████████| 159/159 [00:00<00:00, 12994.06it/s]\n",
      "reading all train features from 150s: 100%|██████████| 39/39 [00:00<00:00, 271.57it/s]\n",
      "reading all test features from 150s: 100%|██████████| 39/39 [00:00<00:00, 2909.81it/s]\n",
      "reading all train features from 300s: 100%|██████████| 39/39 [00:00<00:00, 222.12it/s]\n",
      "reading all test features from 300s: 100%|██████████| 39/39 [00:00<00:00, 2413.33it/s]\n",
      "reading all train features from 450s: 100%|██████████| 39/39 [00:00<00:00, 210.49it/s]\n",
      "reading all test features from 450s: 100%|██████████| 39/39 [00:00<00:00, 2841.23it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_0.to_feather('preprocessing/train')\n",
    "X_test_0.to_feather('preprocessing/test')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "377410b2ba9df469234bd6844d6b90cef95175d2cd66e3643877be8dcce27c77"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}